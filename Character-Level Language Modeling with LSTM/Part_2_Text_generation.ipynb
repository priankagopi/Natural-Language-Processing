{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AGBkn-0NhlP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow.compat.v1 as tf\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras import utils as np_utils \n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the text file and convert texts to lowercase\n",
        "with open('/content/drive/MyDrive/data/shakespeare.txt', 'r') as f:\n",
        "    text = f.read().lower()\n",
        "\n",
        "# create a set of all unique characters in the text\n",
        "chars = sorted(list(set(text)))"
      ],
      "metadata": {
        "id": "UCpSqlXXOhXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dictionary to map characters to integers and vice versa\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "idx_to_char = {i: c for i, c in enumerate(chars)}"
      ],
      "metadata": {
        "id": "5ErUfeRePCpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size of the vocabulary\n",
        "\n",
        "vocab_size = len(chars)\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a7s0btNPGy1",
        "outputId": "8c2fa778-f9ee-4dae-8c30-04abf8e30749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of characters\n",
        "\n",
        "n_chars = len(text)\n",
        "n_chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05EKo-uUPJPQ",
        "outputId": "bb2fdaa8-da2a-426a-8ac6-6923d543d082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93677"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the dataset of input to output encoded as integers \n",
        "\n",
        "seq_length = 40\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(0, n_chars-seq_length,3):\n",
        " seq_in = text[i:i + seq_length]\n",
        " seq_out = text[i + seq_length]\n",
        " X.append([char_to_int[char] for char in seq_in])\n",
        " Y.append(char_to_int[seq_out])"
      ],
      "metadata": {
        "id": "HmyJBeoXPLRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_patterns = len(X)\n",
        "print (\"Total Patterns: \"), n_patterns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSTXrnUyPNsE",
        "outputId": "0cbc5a15-217a-4aa2-cac1-95c4a5592013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 93657)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.reshape(X, (n_patterns, seq_length, 1))\n",
        "\n",
        "X = X / float(vocab_size)   # normalize\n",
        "y = to_categorical(Y)   # one hot encode the output variable"
      ],
      "metadata": {
        "id": "-3FF0hjVPP5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "\n",
        "# define the LSTM model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))"
      ],
      "metadata": {
        "id": "ffNFi-LbPSLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "filepath=\"/content/drive/MyDrive/Weights/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "HtV7Guy0PUcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\") #optimize the model"
      ],
      "metadata": {
        "id": "5lJbr-4TPWeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the network weights\n",
        "\n",
        "filename = \"/content/drive/MyDrive/data/weights-improvement-914-0.0221.hdf5\"\n",
        "model.load_weights(filename, True)"
      ],
      "metadata": {
        "id": "773ZgBVnQLaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJQRhBOPj4rA",
        "outputId": "2f48ff64-e574-43e1-a495-07f1ae129095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 512)               1052672   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 38)                19494     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,072,166\n",
            "Trainable params: 1,072,166\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers: print(layer.get_config(), layer.get_weights())       # display the weights which were loaded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gw-2BBXkGQb",
        "outputId": "61ccee88-79ab-41d7-dedb-8e2b341ff416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'lstm', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 20, 1), 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 512, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2} [array([[-0.35341662,  0.44983524, -0.9613208 , ...,  0.08878878,\n",
            "         0.2943596 , -0.6850567 ]], dtype=float32), array([[ 1.6965122 , -0.35287204, -0.74266505, ...,  0.5520702 ,\n",
            "         1.7889847 ,  0.20906772],\n",
            "       [-0.28166452, -1.041133  , -2.2316506 , ..., -0.05953772,\n",
            "        -2.3170688 , -0.4839433 ],\n",
            "       [ 0.68809533,  0.09826288,  0.9587949 , ..., -0.85307693,\n",
            "        -0.41103762,  0.61715305],\n",
            "       ...,\n",
            "       [-0.08835759, -0.44781336, -0.63843775, ..., -0.4882563 ,\n",
            "         1.0610034 ,  0.81924534],\n",
            "       [-1.5304908 , -0.41805813, -0.8229449 , ...,  0.7570737 ,\n",
            "        -1.0616688 ,  0.20624535],\n",
            "       [-0.51350206, -0.01083228,  1.5684128 , ...,  1.0947237 ,\n",
            "         0.53352886, -1.3307705 ]], dtype=float32), array([-1.1716211 , -2.080998  , -1.4109524 , ..., -1.2044204 ,\n",
            "       -0.96569866, -1.6114445 ], dtype=float32)]\n",
            "{'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None} []\n",
            "{'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 38, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None} [array([[-5.39563820e-02, -1.54290414e+00,  2.98469925e+00, ...,\n",
            "        -2.55610013e+00,  9.13509607e-01,  3.42882419e+00],\n",
            "       [-8.61159706e+00,  1.41870547e-02, -1.16914940e+00, ...,\n",
            "        -3.45232129e-01, -1.95421362e+00,  2.51887560e-01],\n",
            "       [ 1.17858835e-01, -7.50477791e-01,  4.31580096e-01, ...,\n",
            "        -1.44009554e+00, -2.44806074e-02, -3.53338523e-03],\n",
            "       ...,\n",
            "       [ 1.90165973e+00,  9.10804272e-01, -2.30126071e+00, ...,\n",
            "        -3.82819444e-01,  1.52187061e+00,  8.06872070e-01],\n",
            "       [ 5.86610019e-01,  5.92708588e-01, -3.58934104e-01, ...,\n",
            "        -1.50648010e+00,  3.57488662e-01, -3.56254610e-03],\n",
            "       [ 3.80163574e+00,  2.29122615e+00,  1.40353680e-01, ...,\n",
            "         3.44201064e+00,  1.51318240e+00, -3.34990287e+00]], dtype=float32), array([-1.7229633 ,  1.4680859 , -0.90278906, -0.18740703, -1.5632203 ,\n",
            "       -1.3449737 ,  0.27847254, -0.87324244, -2.4133239 , -2.0857992 ,\n",
            "       -1.0560025 , -1.9690706 , -0.16388546, -0.62701476, -0.7334559 ,\n",
            "       -0.21373193,  0.3721729 , -0.16799916, -0.4229454 , -0.44807023,\n",
            "       -2.0147479 , -2.1323042 , -1.4205211 ,  0.23307167, -0.2646805 ,\n",
            "        1.579471  , -0.01808368, -2.950282  , -2.577024  , -0.46127984,\n",
            "       -1.1961524 ,  0.5657316 , -0.31573415,  0.00954655, -0.23899543,\n",
            "       -1.9252902 ,  0.45539635, -0.9871827 ], dtype=float32)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicting and Sampling : Generate 100-character sequence."
      ],
      "metadata": {
        "id": "AnBruYLnG48V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters (1000)\n",
        "\n",
        "def generate_text(text):\n",
        "    text = str (text)\n",
        "    vector=[char_to_int[char] for char in text [-seq_length:]]\n",
        "    output = text\n",
        "    for i in range(1000):\n",
        "        iseq = np.reshape(vector,(1,len(vector), 1))\n",
        "        iseq = iseq / float(len(chars))\n",
        "\n",
        "        pred = np.argmax(model.predict(iseq, verbose=0))\n",
        "        seq = [idx_to_char[value] for value in vector]\n",
        "\n",
        "        output += idx_to_char[pred]\n",
        "\n",
        "        vector.append(pred)\n",
        "        vector = vector[1:len(vector)]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "EAeGYYiZ8Rwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input sequences for testing\n",
        "\n",
        "shapespeare1 = \"Look in thy glass and tell the\"\n",
        "shapespeare2 = \"Thy youth's proud livery so gazed on now,\"\n",
        "shapespeare3 = \"leads summer on\""
      ],
      "metadata": {
        "id": "ElAWJM3K8t3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text generation 1\n",
        "\n",
        "output1 = generate_text(shapespeare1.lower())\n",
        "print(output1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bLtWCks8wwl",
        "outputId": "86bd038e-b24f-4d66-e5f1-f738671a877f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "look in thy glass and tell the face thou viewest,\n",
            "now is the time that face should form another,\n",
            "whose fresh repair if now thou not renewest,\n",
            "thou dost beguile the world, unbless some mother.\n",
            "for where is she so fair whose uneared womb\n",
            "disdains the tillage of thy husbandry?\n",
            "or who is he so fond will be the tomb,\n",
            "of his self-love to stop posterity?  \n",
            "thou art thy mother's glass and she in thee\n",
            "calls back the lovely april of her prime,\n",
            "so thou through windows of thine age shalt see,\n",
            "despite of wrinkles this thy golden time.\n",
            "but if thou live remembered not to be,\n",
            "die single and thine image dies with thee.\n",
            "\n",
            "unthrifty loveliness why dost thou spend,\n",
            "upon thy self thy beauty's legacy?\n",
            "nature's bequest gives nothing but doth lend,\n",
            "and being frank she lends to those are free:\n",
            "then beauteous niggard why dost thou abuse,\n",
            "the bounteous largess given thee to give?\n",
            "profitless usurer why dost thou use\n",
            "so great a sum of sums yet canst not live?\n",
            "for having traffic with thy self alone,\n",
            "thou of thy self thy sweet self dost deceive,\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Evaluation : Generate a 400-character sequence"
      ],
      "metadata": {
        "id": "SGP4mVbAGtNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate characters (400)\n",
        "\n",
        "def generate_text_400(text):\n",
        "    text = str (text)\n",
        "    vector=[char_to_int[char] for char in text [-seq_length:]]\n",
        "    output = text\n",
        "    for i in range(400):\n",
        "        iseq = np.reshape(vector,(1,len(vector), 1))\n",
        "        iseq = iseq / float(len(chars))\n",
        "\n",
        "        pred = np.argmax(model.predict(iseq, verbose=0))\n",
        "        seq = [idx_to_char[value] for value in vector]\n",
        "\n",
        "        output += idx_to_char[pred]\n",
        "\n",
        "        vector.append(pred)\n",
        "        vector = vector[1:len(vector)]\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "c5xlozASntDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Text generation 2\n",
        "\n",
        "shakespeare_text1 = generate_text_400(shapespeare1.lower())\n",
        "print(shakespeare_text1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3JjIiWvn5w1",
        "outputId": "fc7726df-2343-476f-e20d-fa49575df08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "look in thy glass and tell the face thou viewest,\n",
            "now is the time that face should form another,\n",
            "whose fresh repair if now thou not renewest,\n",
            "thou dost beguile the world, unbless some mother.\n",
            "for where is she so fair whose uneared womb\n",
            "disdains the tillage of thy husbandry?\n",
            "or who is he so fond will be the tomb,\n",
            "of his self-love to stop posterity?  \n",
            "thou art thy mother's glass and she in thee\n",
            "calls back the lovely april of her\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text generation 2\n",
        "\n",
        "shakespeare_text2 = generate_text_400(shapespeare2.lower())\n",
        "print(shakespeare_text2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opG3hUXk0fh6",
        "outputId": "326ab587-15be-40ef-bec1-e5b2608a1766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thy youth's proud livery so gazed on now,\n",
            "will be a tattered weed of small worth held:  \n",
            "then being asked, where all thy beauty lies,\n",
            "where all the treasure of thy lusty days;\n",
            "to say within thine own deep sunken eyes,\n",
            "were an all-eating shame, and thriftless praise.\n",
            "how much more praise deserved thy beauty's use,\n",
            "if thou couldst answer 'this fair child of mine\n",
            "shall sum my count, and make my old excuse'\n",
            "proving his beauty by succession t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Text generation 3\n",
        "\n",
        "shakespeare_text3 = generate_text_400(shapespeare3.lower())\n",
        "print(shakespeare_text3)"
      ],
      "metadata": {
        "id": "r9gS6wbKXXTh",
        "outputId": "f2a6540c-266b-435e-bf4c-cc528e487aaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "leads summer on thee,\n",
            "the parn mf toue that lo toue sote canken th thee,\n",
            "whene thou mhs'st tho whrl woite no wamde tho benuty oafn the blned that benngd the clne so thee,\n",
            "when yhu bet ey lans ball ant fere whel thou dest ro geed the cank shee thet goeee\n",
            "th thee,\n",
            "where yhu hen lo heart which tho geld she blnude to the benean whth thee wout pelf io whnter stblt,\n",
            "what shou dost banu wilh then ganeen flr thy love, t\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "30ip6aUkYZ4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}