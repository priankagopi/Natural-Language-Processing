{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9pmNbsqJ3ox",
        "outputId": "61f90a79-0560-43eb-c35b-09a43dcaed2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import contractions\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "lemmatizer = WordNetLemmatizer() "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read train data\n",
        "train = pd.read_csv(\"/content/drive/MyDrive/data/imdb_train.csv\")\n",
        "\n",
        "# Read test data\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/data/imdb_test.csv\")"
      ],
      "metadata": {
        "id": "1RLewNzvLs4u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_input_data(txt):\n",
        "        TAG_RE = re.compile(r'<[^>]+>')                                  # html codes\n",
        "        txt = TAG_RE.sub('', txt.lower())\n",
        "\n",
        "        txt=txt.encode(\"ascii\",\"ignore\")                                 # emojis\n",
        "        txt=txt.decode()\n",
        "\n",
        "        txt=''.join(i for i in txt if not i.isdigit())                   # numbers\n",
        "        txt = re.sub(r'[^\\w\\s]', ' ', txt)                               # punctuations\n",
        "\n",
        "        txt = ' '.join([i for i in txt.split() if not i in STOPWORDS])   # stopwords\n",
        "\n",
        "        txt=' '.join([i for i in txt.split() if len(i)>2])\n",
        "\n",
        "        txt=contractions.fix(txt)\n",
        "\n",
        "        txt=lemmatizer.lemmatize(txt)                                    # lematization\n",
        "        return txt"
      ],
      "metadata": {
        "id": "MXdGFgY0LEBj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text']=train['text'].apply(clean_input_data)\n",
        "test['text']=test['text'].apply(clean_input_data)"
      ],
      "metadata": {
        "id": "rbyl54FZM0II"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the train and test data\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "shuffle(train)\n",
        "shuffle(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DJQUu7kgLEPU",
        "outputId": "8202c4dc-be63-491d-f309-efa6b151fff0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "286    first movie ever saw life back years old time ...      1\n",
              "21974  tagline lucky ones died watching never watched...      0\n",
              "4144   first entire script mostly improv adding fanta...      1\n",
              "20883  saw cinema initial release ask world gone mad ...      0\n",
              "4221   watched gundam time much better gundam wing wa...      1\n",
              "...                                                  ...    ...\n",
              "1407   pleasure seeing saltimbanco live seeing video ...      1\n",
              "8522   bizarre experiment astronaut abandoned moon al...      1\n",
              "22428  film unbelievable level fails action film one ...      0\n",
              "7614   camerawork certainly funky perhaps one dutch r...      1\n",
              "2817   great film gratuitous gimmicks like hollywood ...      1\n",
              "\n",
              "[25000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d50779e9-82df-4d76-9004-04e936fec94d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>first movie ever saw life back years old time ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21974</th>\n",
              "      <td>tagline lucky ones died watching never watched...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4144</th>\n",
              "      <td>first entire script mostly improv adding fanta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20883</th>\n",
              "      <td>saw cinema initial release ask world gone mad ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4221</th>\n",
              "      <td>watched gundam time much better gundam wing wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1407</th>\n",
              "      <td>pleasure seeing saltimbanco live seeing video ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8522</th>\n",
              "      <td>bizarre experiment astronaut abandoned moon al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22428</th>\n",
              "      <td>film unbelievable level fails action film one ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7614</th>\n",
              "      <td>camerawork certainly funky perhaps one dutch r...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2817</th>\n",
              "      <td>great film gratuitous gimmicks like hollywood ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d50779e9-82df-4d76-9004-04e936fec94d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d50779e9-82df-4d76-9004-04e936fec94d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d50779e9-82df-4d76-9004-04e936fec94d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prepare the data for modelling\n",
        "\n",
        "x_train = train.text\n",
        "y_train = train.label\n",
        "x_test = test.text\n",
        "y_test = test.label"
      ],
      "metadata": {
        "id": "m70kO93HN3ea"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import text, sequence\n",
        "max_features = 10000\n",
        "max_len = 128\n",
        "\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(x_train)"
      ],
      "metadata": {
        "id": "3tKV9Nw7mzfR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import pad_sequences\n",
        "\n",
        "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
        "X_train = pad_sequences(tokenized_train, maxlen=max_len)\n",
        "\n",
        "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
        "X_test = pad_sequences(tokenized_test, maxlen=max_len) "
      ],
      "metadata": {
        "id": "-BNVXOvBnXqG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the GloVe embeddings file\n",
        "GLOVE_EMB_DIR = '/content/drive/MyDrive/data/glove.6B.50d.txt'"
      ],
      "metadata": {
        "id": "KYmjGgU6oGFC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coeffs(word, *arr):\n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_dict = dict(get_coeffs(*o.rstrip().rsplit(' ')) for o in open(GLOVE_EMB_DIR))"
      ],
      "metadata": {
        "id": "cBer7vM_oA70"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_embs = np.stack(embeddings_dict.values())\n",
        "emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
        "embed_size = all_embs.shape[1]\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(max_features, len(word_index))\n",
        "\n",
        "embedding_matrix = np.random.normal(emb_mean, emb_std, (num_words, embed_size))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    \n",
        "    if i >= num_words: continue\n",
        "    embedding_vector = embeddings_dict.get(word)\n",
        "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEFvKZ8ioFx8",
        "outputId": "90c48d55-aa87-4861-9231-032841592a66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 10000\n",
        "max_len = 128\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.00001)"
      ],
      "metadata": {
        "id": "zTVSWAGaoYq9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(max_features, output_dim=embed_size, weights=[embedding_matrix], input_length=max_len, trainable=False))\n",
        "model.add(Bidirectional(LSTM(units=128)))\n",
        "model.add(Dropout(rate=0.8))\n",
        "model.add(Dense(units=16, activation='relu'))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(lr=0.002), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLNf865OoY51",
        "outputId": "14b724c9-5db7-49dd-cc62-0ab0657bbc58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrazWhetoZGi",
        "outputId": "d9a5730d-05ab-4805-fd49-108727ed65aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 128, 50)           500000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              183296    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                4112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 687,425\n",
            "Trainable params: 187,425\n",
            "Non-trainable params: 500,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "epochs=10\n",
        "embed_size=50\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), callbacks=[learning_rate_reduction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiFYsNRoo7yg",
        "outputId": "749abb9b-bc46-4f21-f631-7371706a02b2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "98/98 [==============================] - 209s 2s/step - loss: 0.6091 - accuracy: 0.6656 - val_loss: 0.5056 - val_accuracy: 0.7606 - lr: 0.0020\n",
            "Epoch 2/10\n",
            "98/98 [==============================] - 185s 2s/step - loss: 0.4913 - accuracy: 0.7692 - val_loss: 0.4396 - val_accuracy: 0.7938 - lr: 0.0020\n",
            "Epoch 3/10\n",
            "98/98 [==============================] - 222s 2s/step - loss: 0.4355 - accuracy: 0.8065 - val_loss: 0.3947 - val_accuracy: 0.8231 - lr: 0.0020\n",
            "Epoch 4/10\n",
            "98/98 [==============================] - 170s 2s/step - loss: 0.4030 - accuracy: 0.8230 - val_loss: 0.3836 - val_accuracy: 0.8333 - lr: 0.0020\n",
            "Epoch 5/10\n",
            "98/98 [==============================] - 202s 2s/step - loss: 0.3887 - accuracy: 0.8300 - val_loss: 0.3800 - val_accuracy: 0.8298 - lr: 0.0020\n",
            "Epoch 6/10\n",
            "98/98 [==============================] - 203s 2s/step - loss: 0.3749 - accuracy: 0.8398 - val_loss: 0.4075 - val_accuracy: 0.8233 - lr: 0.0020\n",
            "Epoch 7/10\n",
            "98/98 [==============================] - 203s 2s/step - loss: 0.3587 - accuracy: 0.8477 - val_loss: 0.3517 - val_accuracy: 0.8460 - lr: 0.0020\n",
            "Epoch 8/10\n",
            "98/98 [==============================] - 203s 2s/step - loss: 0.3553 - accuracy: 0.8492 - val_loss: 0.3481 - val_accuracy: 0.8507 - lr: 0.0020\n",
            "Epoch 9/10\n",
            "98/98 [==============================] - 173s 2s/step - loss: 0.3355 - accuracy: 0.8608 - val_loss: 0.3398 - val_accuracy: 0.8528 - lr: 0.0020\n",
            "Epoch 10/10\n",
            "98/98 [==============================] - 203s 2s/step - loss: 0.3289 - accuracy: 0.8618 - val_loss: 0.3347 - val_accuracy: 0.8519 - lr: 0.0020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = (y_pred > 0.6)\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "metadata": {
        "id": "F8sJeXUOBFRj",
        "outputId": "c6b673d3-0439-4f73-eaae-dce802bcb861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 91s 116ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.90      0.85     12500\n",
            "           1       0.89      0.78      0.83     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.85      0.84      0.84     25000\n",
            "weighted avg       0.85      0.84      0.84     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jJU_Nn8dKbWc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}